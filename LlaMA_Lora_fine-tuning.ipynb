{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73eede96",
   "metadata": {},
   "source": [
    "**基于MindSpore的LlaMA模型微调**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2fb3f2",
   "metadata": {},
   "source": [
    "数据集准备\n",
    "\n",
    "**School Math 0.25M Dataset**\n",
    "\n",
    "包含约25万条由BELLE项目生成的中文数学题数据, 包含解题过程。 注意: 此数据集是由ChatGPT产生的, 未经过严格校验, 题目或解题过程可能包含错误。使用过程中请注意这一点\n",
    "```\n",
    "{\n",
    "  \"instruction\": \"题目：小华手里有一个装满糖果的袋子，共有12个，小明想知道里面有多少颗糖果，于是他问小华：“你手里的糖果袋子里有偶数个糖果吗？”小华回答：“有，而且多于10颗。”请问小华手里的糖果袋子里最少有几颗糖果？\",\n",
    "  \"input\": \"\",\n",
    "  \"output\": \"\\n由题目可知：小华手里的糖果袋子里有偶数个糖果；\\n又知道小华手里的糖果袋子里有多于10颗糖果。\\n因为糖果数为偶数，多于10颗，所以糖果数最小必须是12。\\n所以小华手里的糖果袋子里最少有12颗糖果。\"\n",
    "}\n",
    "```\n",
    "**下载数据**\n",
    "```\n",
    "wget https://huggingface.co/datasets/BelleGroup/school_math_0.25M/resolve/main/school_math_0.25M.json\n",
    "```\n",
    "\n",
    "执行converter.py，使用fastchat工具添加prompts模板，将原始数据集转换为多轮对话格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a23ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python converter.py --data_path  ./data/school_math_0.25M.json --output_path  school_math-data-conversation.json "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882fcd38",
   "metadata": {},
   "source": [
    "转换后格式样例：\n",
    "```\n",
    "{\"id\": \"bellemath42\", \"conversations\": [{\"from\": \"human\", \"value\": \" 题目：小华手里有一个装满糖果的袋子，共有12个，小明想知道里面有多少颗糖果，于是他问小华：“你手里的糖果袋子里有偶数个糖果吗？”小华回答：“有，而且多于10颗。”请问小华手里的糖果袋子里最少有几颗糖果？\"}, \n",
    "{\"from\": \"assistant\", \"value\": \"\\n由题目可知：小华手里的糖果袋子里有偶数个糖果；\\n又知道小华手里的糖果袋子里有多于10颗糖果。\\n因为糖果数为偶数，多于10颗，所以糖果数最小必须是12。\\n所以小华手里的糖果袋子里最少有12颗糖果。\"}]}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d943cc",
   "metadata": {},
   "source": [
    "执行preprocess.py，进行数据预处理、Mindrecord数据生成，将带有prompt模板的数据转换为mindrecord格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26b32b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 脚本路径：preprocess.py \n",
    "!python preprocess.py --dataset_type  qa --input_glob  school_math-data-conversation.json --model_file  ./checkpoint_download/llama/tokenizer.model --seq_length  2048 --output_file  belleMath2048.mindrecord "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9d8891",
   "metadata": {},
   "source": [
    "***lora微调***\n",
    "\n",
    "lora微调支持使用高阶接口启动单卡微调任务"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2e917e",
   "metadata": {},
   "source": [
    "修改run_llama_7b—lora.yaml 中训练数据集路径为微调数据集路径，并在input_columns中添加labels。\n",
    "**将任务配置文件 run_llama_7b_lora.yaml 中的 ==== dataset config ==== 部分替换成：**\n",
    "```\n",
    "train_dataset: &train_dataset\n",
    "  data_loader:\n",
    "    type: MindDataset\n",
    "    dataset_dir: \"\"\n",
    "    shuffle: True\n",
    "  input_columns: [\"input_ids\", \"labels\"]  # \"input_ids\", \"labels\" , labels are used in instruction finetune.\n",
    "  num_parallel_workers: 8\n",
    "  python_multiprocessing: False\n",
    "  drop_remainder: True\n",
    "  batch_size: 2\n",
    "  repeat: 1\n",
    "  numa_enable: False\n",
    "  prefetch_size: 1\n",
    "\n",
    "train_dataset_task:\n",
    "  type: CausalLanguageModelDataset\n",
    "  dataset_config: *train_dataset\n",
    "# if True, do evaluate during the training process. if false, do nothing.\n",
    "# note that the task trainer should support _evaluate_in_training function.\n",
    "do_eval: False\n",
    "\n",
    "# eval dataset\n",
    "eval_dataset: &eval_dataset\n",
    "  data_loader:\n",
    "    type: MindDataset\n",
    "    dataset_dir: \"\"\n",
    "    shuffle: False\n",
    "  input_columns: [\"input_ids\", \"labels\"]\n",
    "  num_parallel_workers: 8\n",
    "  python_multiprocessing: False\n",
    "  drop_remainder: False\n",
    "  repeat: 1\n",
    "  numa_enable: False\n",
    "  prefetch_size: 1\n",
    "eval_dataset_task:\n",
    "  type: CausalLanguageModelDataset\n",
    "  dataset_config: *eval_dataset\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9f74b3",
   "metadata": {},
   "source": [
    "修改训练时学习率和优化器参数，与预训练不同，微调学习率配置如下：\n",
    "```\n",
    "# optimizer\n",
    "optimizer:\n",
    "  type: FP32StateAdamWeightDecay\n",
    "  beta1: 0.9\n",
    "  beta2: 0.999\n",
    "  eps: 1.e-8\n",
    "  learning_rate: 1.e-5\n",
    "\n",
    "# lr sechdule\n",
    "lr_schedule:\n",
    "  type: CosineWithWarmUpLR\n",
    "  learning_rate: 1.e-5\n",
    "  warmup_ratio: 0.03\n",
    "  total_steps: -1 # -1 means it will load the total steps of the dataset\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44312b9b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import  mindspore ;  \n",
    "mindspore . set_context ( mode = 0 ,  device_id = 0 ) \n",
    "from  mindformers.trainer  import  Trainer \n",
    "# Initialize the pre-training task \n",
    "trainer  =  Trainer ( task = 'text_generation' , \n",
    "                  model = 'llama_7b' , \n",
    "                  args = 'run_llama_6b_lora.yaml',\n",
    "                  pet_method = 'lora' , \n",
    "                  train_dataset = \"belleMath2048.mindrecord\" ) \n",
    "#  Call the finetune interface to fine-tune \n",
    "trainer . finetune ( finetune_checkpoint = \"./checkpoint_download/llama/llama_7b.ckpt\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ab0396",
   "metadata": {},
   "source": [
    "**推理**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc1ddb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import mindspore as ms\n",
    "from mindspore.train import Model\n",
    "from mindspore import load_checkpoint, load_param_into_net\n",
    "\n",
    "from mindformers import AutoConfig, AutoTokenizer, AutoModel, pipeline\n",
    "from mindformers import init_context, ContextConfig, ParallelContextConfig\n",
    "from mindformers.trainer.utils import get_last_checkpoint\n",
    "from mindformers.tools.utils import str2bool, get_real_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec36f4b1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def context_init(use_parallel=False, device_id=0):\n",
    "    \"\"\"init context for mindspore.\"\"\"\n",
    "    context_config = ContextConfig(mode=0, device_target=\"Ascend\", device_id=device_id)\n",
    "    parallel_config = None\n",
    "    if use_parallel:\n",
    "        parallel_config = ParallelContextConfig(parallel_mode='SEMI_AUTO_PARALLEL',\n",
    "                                                gradients_mean=False,\n",
    "                                                full_batch=True)\n",
    "    init_context(use_parallel=use_parallel,\n",
    "                 context_config=context_config,\n",
    "                 parallel_config=parallel_config)\n",
    "\n",
    "\n",
    "model_type='llama_7b'\n",
    "use_parallel=False\n",
    "device_id=0\n",
    "checkpoint_path=\"./output/checkpoint/rank_0/llama_7b_lora_rank_0-50_2.ckpt\"\n",
    "use_past=True\n",
    "# 初始化单卡/多卡环境\n",
    "context_init(use_parallel, device_id)\n",
    "\n",
    "# set model config\n",
    "model_config = AutoConfig.from_pretrained(model_type)\n",
    "model_config.use_past = use_past\n",
    "\n",
    "model_config.parallel_config.data_parallel = 1\n",
    "model_config.parallel_config.model_parallel = 1\n",
    "model_config.checkpoint_name_or_path = checkpoint_path\n",
    "print(f\"config is: {model_config}\")\n",
    "\n",
    "# build tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_type)\n",
    "# build model from config\n",
    "network = AutoModel.from_config(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3474a3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-23 10:23:50,514 - mindformers[mindformers/generation/text_generator.py:1105] - WARNING - When do_sample is set to False, top_k will be set to 1 and top_p will be set to 0, making them inactive.\n",
      "2024-01-23 10:23:50,518 - mindformers[mindformers/generation/text_generator.py:1109] - INFO - Generation Config is: {'max_length': 512, 'max_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1.0, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 0, 'bos_token_id': 1, 'eos_token_id': 2, '_from_model_config': True}\n",
      "2024-01-23 10:23:50,522 - mindformers[mindformers/generation/text_generator.py:176] - INFO - The generation mode will be **GREEDY_SEARCH**.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-23 10:29:26,169 - mindformers[mindformers/generation/text_generator.py:478] - INFO - total time: 335.64381980895996 s; generated tokens: 506 tokens; generate speed: 1.5075504750482298 tokens/s\n",
      "2024-01-23 10:29:26,251 - mindformers[mindformers/generation/text_generator.py:1105] - WARNING - When do_sample is set to False, top_k will be set to 1 and top_p will be set to 0, making them inactive.\n",
      "2024-01-23 10:29:26,253 - mindformers[mindformers/generation/text_generator.py:1109] - INFO - Generation Config is: {'max_length': 512, 'max_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1.0, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 0, 'bos_token_id': 1, 'eos_token_id': 2, '_from_model_config': True}\n",
      "2024-01-23 10:29:26,255 - mindformers[mindformers/generation/text_generator.py:176] - INFO - The generation mode will be **GREEDY_SEARCH**.\n",
      "2024-01-23 10:29:49,065 - mindformers[mindformers/generation/text_generator.py:478] - INFO - total time: 22.80844521522522 s; generated tokens: 506 tokens; generate speed: 22.18476512648184 tokens/s\n",
      "2024-01-23 10:29:49,152 - mindformers[mindformers/generation/text_generator.py:1105] - WARNING - When do_sample is set to False, top_k will be set to 1 and top_p will be set to 0, making them inactive.\n",
      "2024-01-23 10:29:49,153 - mindformers[mindformers/generation/text_generator.py:1109] - INFO - Generation Config is: {'max_length': 512, 'max_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1.0, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 0, 'bos_token_id': 1, 'eos_token_id': 2, '_from_model_config': True}\n",
      "2024-01-23 10:29:49,154 - mindformers[mindformers/generation/text_generator.py:176] - INFO - The generation mode will be **GREEDY_SEARCH**.\n",
      "2024-01-23 10:30:12,307 - mindformers[mindformers/generation/text_generator.py:478] - INFO - total time: 23.15195918083191 s; generated tokens: 506 tokens; generate speed: 21.855601767773077 tokens/s\n",
      "{'text_generation_text': ['I love Beijing, because it is a city that is constantly changing. It is a city that is constantly evolving. It is a city that is constantly growing. It is a city that is constantly developing. It is a city that is constantly changing. It is a city that is constantly evolving. It is a city that is constantly growing. It is a city that is constantly developing. It is a city that is constantly changing. It is a city that is constantly evolving. It is a city that is constantly growing. It is a city that is constantly developing. It is a city that is constantly changing. It is a city that is constantly evolving. It is a city that is constantly growing. It is a city that is constantly developing. It is a city that is constantly changing. It is a city that is constantly evolving. It is a city that is constantly growing. It is a city that is constantly developing. It is a city that is constantly changing. It is a city that is constantly evolving. It is a city that is constantly growing. It is a city that is constantly developing. It is a city that is constantly changing. It is a city that is constantly evolving. It is a city that is constantly growing. It is a city that is constantly developing. It is a city that is constantly changing. It is a city that is constantly evolving. It is a city that is constantly growing. It is a city that is constantly developing. It is a city that is constantly changing. It is a city that is constantly evolving. It is a city that is constantly growing. It is a city that is constantly developing. It is a city that is constantly changing. It is a city that is constantly evolving. It is a city that is constantly growing. It is a city that is constantly developing. It is a city that is constantly changing. It is a city that is constantly evolving. It is a city that is constantly growing. It is a city that is constantly developing. It is a city that is constantly changing. It is a city that is constantly evolving. It is a city that is constantly growing. It is a city that is constantly developing. It is a city that is constantly changing. It is a city that is constantly evolving. It is a city that is constantly growing. It is a city that is constantly developing. It is a city that is constantly changing. It is a city that is constantly evolving. It is a city that is constantly growing. It is a city that is constantly developing. It is']}\n",
      "{'text_generation_text': ['LLaMA is a non-profit organization that provides a safe and supportive environment for people with mental illness to live, work, and participate in the community.\\nLaMA is a non-profit organization that provides a safe and supportive environment for people with mental illness to live, work, and participate in the community.\\nLaMA is a non-profit organization that provides a safe and supportive environment for people with mental illness to live, work, and participate in the community. LaMA is a non-profit organization that provides a safe and supportive environment for people with mental illness to live, work, and participate in the community.\\nLaMA is a non-profit organization that provides a safe and supportive environment for people with mental illness to live, work, and participate in the community. LaMA is a non-profit organization that provides a safe and supportive environment for people with mental illness to live, work, and participate in the community.\\nLaMA is a non-profit organization that provides a safe and supportive environment for people with mental illness to live, work, and participate in the community. LaMA is a non-profit organization that provides a safe and supportive environment for people with mental illness to live, work, and participate in the community.\\nLaMA is a non-profit organization that provides a safe and supportive environment for people with mental illness to live, work, and participate in the community. LaMA is a non-profit organization that provides a safe and supportive environment for people with mental illness to live, work, and participate in the community.\\nLaMA is a non-profit organization that provides a safe and supportive environment for people with mental illness to live, work, and participate in the community. LaMA is a non-profit organization that provides a safe and supportive environment for people with mental illness to live, work, and participate in the community.\\nLaMA is a non-profit organization that provides a safe and supportive environment for people with mental illness to live, work, and participate in the community. LaMA is a non-profit organization that provides a safe and supportive environment for people with mental illness to live, work, and participate in the community.\\nLaMA is a non-profit organization that provides a safe and supportive environment for people with mental illness to live, work, and participate in the community. LaMA is a non-profit organization that provides a safe and supportive environment for people with mental illness to live, work, and participate in the community.\\nLaMA is a non']}\n",
      "{'text_generation_text': ['Huawei is a company that has been around for a long time. They are a Chinese company that has been making phones for a long time. They are one of the biggest phone manufacturers in the world. They have a lot of different phones that are available for purchase.\\nHuawei is a Chinese company that makes smartphones and other electronic devices. They are one of the biggest phone manufacturers in the world. They have a lot of different phones that are available for purchase.\\nHuawei is a Chinese company that makes smartphones and other electronic devices. They are one of the biggest phone manufacturers in the world. They have a lot of different phones that are available for purchase. Huawei is a Chinese company that makes smartphones and other electronic devices. They are one of the biggest phone manufacturers in the world. They have a lot of different phones that are available for purchase.\\nHuawei is a Chinese company that makes smartphones and other electronic devices. They are one of the biggest phone manufacturers in the world. They have a lot of different phones that are available for purchase. Huawei is a Chinese company that makes smartphones and other electronic devices. They are one of the biggest phone manufacturers in the world. They have a lot of different phones that are available for purchase. Huawei is a Chinese company that makes smartphones and other electronic devices. They are one of the biggest phone manufacturers in the world. They have a lot of different phones that are available for purchase. Huawei is a Chinese company that makes smartphones and other electronic devices. They are one of the biggest phone manufacturers in the world. They have a lot of different phones that are available for purchase. Huawei is a Chinese company that makes smartphones and other electronic devices. They are one of the biggest phone manufacturers in the world. They have a lot of different phones that are available for purchase. Huawei is a Chinese company that makes smartphones and other electronic devices. They are one of the biggest phone manufacturers in the world. They have a lot of different phones that are available for purchase. Huawei is a Chinese company that makes smartphones and other electronic devices. They are one of the biggest phone manufacturers in the world. They have a lot of different phones that are available for purchase. Huawei is a Chinese company that makes smartphones and other electronic devices. They are one of the biggest phone manufacturers in the world. They have a lot of different phones that are available for purchase. Huawei is a Chinese company that makes smartphones and other electronic devices. They are one of the biggest phone manufacturers in the world. They have a lot of different']}\n"
     ]
    }
   ],
   "source": [
    "# 多batch输入\n",
    "inputs = [\"I love Beijing, because\",\n",
    "          \"LLaMA is a\",\n",
    "          \"Huawei is a company that\"]\n",
    "\n",
    "text_generation_pipeline = pipeline(task=\"text_generation\", model=network, tokenizer=tokenizer)\n",
    "outputs = text_generation_pipeline(inputs)\n",
    "for output in outputs:\n",
    "    print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
